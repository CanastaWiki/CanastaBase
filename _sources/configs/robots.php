<?php
# This file pretends to be a /robots.txt file (via Apache rewrite, see configs/mediawiki.conf)

ini_set( 'display_errors', 0 );
error_reporting( 0 );

echo "# The following lines are generated by robots.php\n";

header( 'Content-Type: text/plain' );

$robotsDisallowed = getenv( 'ROBOTS_DISALLOWED' );
if ( !empty( $robotsDisallowed ) && in_array( strtolower($robotsDisallowed), [ 'true', '1' ] ) ) {
	die( "User-agent: *\nDisallow: /\n" );
}

$enableSitemapEnv = getenv( 'MW_ENABLE_SITEMAP_GENERATOR');
// match the value check to the isTrue function at _sources/scripts/functions.sh
if ( !empty( $enableSitemapEnv ) && in_array( $enableSitemapEnv, [ 'true', 'True', 'TRUE', '1' ] ) ) {
	$script = shell_exec( 'php /getMediawikiSettings.php --variable="wgScriptPath" --format="string"' );

	// Determine wiki ID and server from wikis.yaml (wiki farm)
	$wikisYaml = '/mediawiki/config/wikis.yaml';
	if ( file_exists( $wikisYaml ) ) {
		$config = yaml_parse_file( $wikisYaml );
		$serverName = $_SERVER['HTTP_HOST'] ?? 'localhost';
		$serverNameNoPort = preg_replace( '/:.*$/', '', $serverName );
		$wikiId = null;

		if ( isset( $config['wikis'] ) ) {
			foreach ( $config['wikis'] as $wiki ) {
				$wikiUrl = $wiki['url'] ?? '';
				$wikiUrlNoPort = preg_replace( '/:.*$/', '', $wikiUrl );

				if ( $wikiUrl === $serverName ||
				     $wikiUrl === $serverNameNoPort ||
				     $wikiUrlNoPort === $serverName ||
				     $wikiUrlNoPort === $serverNameNoPort ) {
					$wikiId = $wiki['id'];
					break;
				}
			}
		}

		if ( $wikiId ) {
			$scheme = parse_url( getenv( 'MW_SITE_SERVER' ) ?: 'https://localhost', PHP_URL_SCHEME ) ?: 'https';
			$siteMapUrl = "$scheme://$serverName$script/public_assets/sitemap/sitemap-index-$wikiId.xml";
			echo "Sitemap: $siteMapUrl\n";
		}
	} else {
		// Legacy single-wiki: use env vars
		$server = getenv( 'MW_SITE_SERVER' );
		$subdir = getenv( 'MW_SITEMAP_SUBDIR' );
		$identifier = getenv( 'MW_SITEMAP_IDENTIFIER' );
		$siteMapUrl = "$server$script/sitemap$subdir/sitemap-index-$identifier.xml";
		echo "Sitemap: $siteMapUrl\n";
	}

    echo "\n# Content of the robots.txt file:\n";
}

readfile( 'robots-main.txt' );

// If the file `extra-robots.txt` is created under the name
// `/var/www/mediawiki/extra-robots.txt` then its contents get appended to the
// default `robots.txt`
if ( is_readable( 'extra-robots.txt' ) ) {
	// Extra line to separate the files so that rules don't combine
	echo "\n";
	readfile( 'extra-robots.txt' );
}
